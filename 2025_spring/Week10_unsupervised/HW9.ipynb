{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FUApVuJHjfRWQYl-qYR3PjxZCx-ViRtO","timestamp":1699063681620},{"file_id":"1mbfo7xNTgBCC8pQor5r3nzR_zMdHLXF2","timestamp":1699009904569}],"authorship_tag":"ABX9TyOdU7YAvfKgCnGqogX8Qo57"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Homework 9: Neural Network by Hands\n","In this homework, you will work on the classification task with three synthetical datasets: Noisy Moons, Noisy Circles, and a multipetal rose."],"metadata":{"id":"IN6kTlRjzWKw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrLOBVmi4wbF"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_circles, make_moons\n","from mlxtend.plotting import plot_decision_regions"]},{"cell_type":"code","source":["def load_planar_dataset():\n","    np.random.seed(1)\n","    m = 400 # number of examples\n","    N = int(m/2) # number of points per class\n","    D = 2 # dimensionality\n","    X = np.zeros((m,D)) # data matrix where each row is a single example\n","    Y = np.zeros(m, dtype='uint8') # labels vector (0 for red, 1 for blue)\n","    a = 4 # maximum ray of the flower\n","\n","    for j in range(2):\n","        ix = range(N*j,N*(j+1))\n","        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n","        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius. 4 corresponds to the number of petals\n","        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n","        Y[ix] = j\n","\n","    return X, Y"],"metadata":{"id":"pTAn900U4i5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, y = load_planar_dataset()  #make_moons(n_samples=200, noise=0.1)  make_circles(n_samples=200, noise=0.1)\n","y = y.reshape(-1,1)\n","x.shape, y.shape"],"metadata":{"id":"ZG7LwJBT42gG","executionInfo":{"status":"ok","timestamp":1699060569723,"user_tz":240,"elapsed":305,"user":{"displayName":"Anton Selitskii","userId":"15865143011662476323"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"556f4e6e-5dc7-47ce-9b44-13d442827751"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((200, 2), (200, 1))"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["plt.scatter(x[:,0], x[:,1], c=y)"],"metadata":{"id":"5KJi17q-SzDO","executionInfo":{"status":"ok","timestamp":1699063760486,"user_tz":240,"elapsed":5,"user":{"displayName":"Anton Selitskii","userId":"15865143011662476323"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Below is the model from the class: $x\\to h\\to a=\\sigma(h)\\to o\\to Loss(o,y)$, where $Loss$ is MSE:\n","$$\n","Loss(o,y) = \\frac{1}{N} \\sum_{i=1}^{N}\\left( o^{(i)}-y^{(i)}\\right)^2.\n","$$\n","\n","For the binary classification we use binary cross-entropy loss:\n","$$\n","Loss(\\sigma(o^{(i)}),y^{(i)}) = -\\frac{1}{N}\\sum_{i=1}^{N}\\left( y^{(i)}\\log \\sigma(o^{(i)}) + (1-y^{(i)})\\log\\left( 1-\\sigma(o^{(i)})\\right) \\right)\n","$$\n","\n","##Q1 (2pt). Change the model class, applying activation to the output:\n","$x\\to h\\to a=\\sigma(h)\\to o\\to \\sigma(o) \\to Loss(\\sigma(o),y)$\n","\n","##Q2 (5pt). Modify the loss class: the function and the derivative.\n","\n","To avoid devision by zero, add `self.eps = 1e-6`:\n","$$\n","Loss(\\sigma(o^{(i)}),y^{(i)}) = -\\frac{1}{N}\\sum_{i=1}^{N}\\left( y^{(i)}\\log (\\sigma(o^{(i)})+\\varepsilon) + (1-y^{(i)})\\log\\left( 1-\\sigma(o^{(i)})+\\varepsilon\\right) \\right)\n","$$\n","\n","##Q3 (2pt). Change the `predict` method to return $0$ or $1$ instead of $\\sigma(o)$.\n","\n","##Q4 (9pt). Create 3 models for every dataset with sizes of the hidden layer 3, 5, and 10 (9 models in total). You may want to run `.fit` several times with different parameters of `lr` and `n_epochs` to get good separation.\n","Expected code is provided after the model.\n","\n","##Q5 (2pt). Comment on the behavior of the loss function, did you see some jumps (usually with high learning rate), drops, oscillations, etc. Could you explain this? Is the loss function convex with respect to the weights $W$ and baias $b$?"],"metadata":{"id":"rWDtbMC5GEQI"}},{"cell_type":"code","source":["class Loss():\n","  def __init__(self):\n","    self.x_in = None\n","    self.y_in = None\n","    self.eps = 10**(-6)\n","\n","  def forward(self, x_in, y_in):\n","    self.x_in = x_in\n","    self.y_in = y_in\n","    return np.sum((self.x_in-self.y_in)**2)/len(self.x_in) #Change\n","\n","  def backward(self):\n","    return 2*(self.x_in-self.y_in)/len(self.x_in) #Change"],"metadata":{"id":"NSVXMcJnE71d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Activation():\n","  def __init__(self):\n","    self.x_in = None\n","\n","  def forward(self, x_in):\n","    self.x_in = x_in\n","    return 1/(1+np.exp(-self.x_in))\n","\n","  def backward(self, grad, lr=1e-3):\n","    return grad* np.exp(self.x_in)/(1+np.exp(self.x_in))**2"],"metadata":{"id":"e68LbAHTBqeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Linear():\n","  def __init__(self, input_size, output_size):\n","    self.W = np.random.random((output_size, input_size))*0.01\n","    self.b = np.random.random((output_size, 1))*0.01\n","\n","    self.grad_W = np.zeros(self.W.shape)\n","    self.grad_b = np.zeros(self.b.shape)\n","\n","    self.x_in = None\n","\n","  def forward(self, x_in):\n","    self.x_in = x_in\n","    return (self.W.dot(self.x_in.T) + self.b).T\n","\n","  def backward(self, grad, lr=1e-3):\n","    self.grad_W = grad.T @ self.x_in\n","    self.grad_b = grad.T @ np.ones((len(self.x_in),1))\n","    grad = grad @ self.W\n","    self.W -= lr * self.grad_W\n","    self.b -= lr * self.grad_b\n","    return grad"],"metadata":{"id":"cK9PTMJW5OuH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyNN():\n","  def __init__(self, input_size=1, hidden_size=3, output_size=1) -> None:\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.model = [Linear(self.input_size,self.hidden_size), Activation(), Linear(self.hidden_size,self.output_size)] #Change\n","    self.loss = Loss()\n","\n","  def fit(self, x, y, lr=0.01, n_epoch = 1000, warm_start=True):\n","    self.loss_array = []\n","    self.lr = lr\n","    self.n_epoch = n_epoch\n","    if not warm_start:\n","      self.model = [Linear(self.input_size,self.hidden_size), Activation(), Linear(self.hidden_size,self.output_size)] #Change\n","      self.loss = Loss()\n","    for epoc in range(1,self.n_epoch):\n","      x_in = x\n","      y_in = y\n","      for m in self.model:\n","        x_in = m.forward(x_in)\n","      self.loss_array.append(self.loss.forward(x_in, y_in))\n","      grad = self.loss.backward()\n","      for i in range(len(self.model)-1, -1, -1):\n","        grad = self.model[i].backward(grad, lr=self.lr)\n","\n","  def predict(self, x):\n","      x_in = x.reshape(len(x),-1)\n","      for m in self.model:\n","        x_in = m.forward(x_in)\n","      return np.squeeze(x_in) #Change"],"metadata":{"id":"xZRX2A5bwXav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_1 = MyNN(input_size=2, hidden_size=5, output_size=1)"],"metadata":{"id":"-JYk1fkk3CFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_1.fit(x, y, lr=0.1, n_epoch=30000)"],"metadata":{"id":"OLTABp899sFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.plot(model_1.loss_array)"],"metadata":{"id":"HicLh830Kgpe","executionInfo":{"status":"ok","timestamp":1699065442996,"user_tz":240,"elapsed":186,"user":{"displayName":"Anton Selitskii","userId":"15865143011662476323"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#plot_decision_regions(x,y.reshape(-1,),model_1)"],"metadata":{"id":"YOrAU9CbwcYf","executionInfo":{"status":"ok","timestamp":1699065450766,"user_tz":240,"elapsed":4,"user":{"displayName":"Anton Selitskii","userId":"15865143011662476323"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WJTDtAdjE9Wb"},"execution_count":null,"outputs":[]}]}